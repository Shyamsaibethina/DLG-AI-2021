{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a9314ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pickle\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.initializers as initializers\n",
    "import random\n",
    "from matplotlib import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80be4b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self, max_memory):\n",
    "        self.max_memory = max_memory\n",
    "        self.samples = []\n",
    "    \n",
    "    def add_sample(self, sample):\n",
    "        self.samples.append(sample)\n",
    "        if len(self.samples) > self.max_memory:\n",
    "            self.samples.pop(0)\n",
    "            \n",
    "    def sample(self, no_samples):\n",
    "        if no_samples > len(self.samples):\n",
    "            return random.sample(self.samples, len(self.samples))\n",
    "        else:\n",
    "            return random.sample(self.samples, no_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d008aa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = initializers.GlorotNormal\n",
    "\n",
    "x_in = layers.Input(shape = (6400,))\n",
    "x = layers.Dense(200, kernel_initializer= initializer, activation=\"relu\")(x_in)\n",
    "x_out = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(x_in, x_out)\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9196c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = model \n",
    "\n",
    "target_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ddb8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameRunner:\n",
    "    def __init__(self, env, model, target_model, memory, epsilon, max_eps, min_eps, game_dimensions, \n",
    "                 epsilon_greedy_frames, resume = False, render = True):\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.memory = memory\n",
    "        self.eps = epsilon\n",
    "        self.max_eps = max_eps\n",
    "        self.min_eps = min_eps\n",
    "        self.render = render\n",
    "        self.resume = resume\n",
    "        self.epsilon_greedy_frames = epsilon_greedy_frames\n",
    "        self.gameDimensions = game_dimensions\n",
    "        self.rewards = []\n",
    "        self.max_x = []\n",
    "    \n",
    "    def run(self):\n",
    "        observation = self.env.reset()\n",
    "        reward_sum = 0\n",
    "        prev_frame = None\n",
    "        episode_number = 0\n",
    "        recordings = [1, 1000, 2000, 3000, 4000, 5000, 6000]\n",
    "        frames, ep_rewards = [], []\n",
    "        count = 0\n",
    "        \n",
    "        try:\n",
    "            with open(\"DeleteThis.txt\", \"rb\") as fp:   # Unpickling\n",
    "                running_rewards = pickle.load(fp)\n",
    "                resume = True\n",
    "                running_reward = running_rewards[-1]\n",
    "        except:\n",
    "            running_rewards = []\n",
    "            running_reward = None\n",
    "\n",
    "        \n",
    "        while True:\n",
    "            if self.render:\n",
    "                env.render()\n",
    "\n",
    "            if self.resume:\n",
    "                self.model.load_weights(\"ModelWeights\")\n",
    "            \n",
    "            if len(running_rewards) in recordings:\n",
    "                count += 1\n",
    "            \n",
    "            curr_frame = self.prepro(observation)\n",
    "            change_in_frame = curr_frame - prev_frame if prev_frame is not None else np.zeros(self.gameDimensions)\n",
    "            prev_frame = curr_frame\n",
    "            \n",
    "            if (ep_rewards.count(1) + ep_rewards.count(-1) <= 5) and count > 0:\n",
    "                frames.append(observation)\n",
    "            \n",
    "            action, up_prob = self.choose_action(curr_frame)\n",
    "            \n",
    "            observation, reward, done, _ = self.env.step(action) \n",
    "                \n",
    "            y = 1 if action == 2 else 0\n",
    "                        \n",
    "            self.memory.add_sample((change_in_frame, y - up_prob, reward, done))\n",
    "            \n",
    "            # Decay probability of taking random action\n",
    "            epsilon_interval = (self.max_eps - self.min_eps)\n",
    "            self.eps -= epsilon_interval / self.epsilon_greedy_frames\n",
    "            self.eps = max(self.eps, self.min_eps)\n",
    "            \n",
    "            reward_sum += reward\n",
    "            ep_rewards.append(reward)\n",
    "            \n",
    "            if done:\n",
    "                if episode_number % 5 == 0: # Probably should adjust this number\n",
    "                    self.target_model.set_weights(self.model.get_weights())\n",
    "                    self.target_model.save_weights(\"ModelWeights\")\n",
    "                \n",
    "                accuracy, loss = self.replay(self.memory.samples)\n",
    "                self.memory.samples = []\n",
    "                                \n",
    "                running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
    "                print ('resetting env. episode reward total was %f. running mean: %f. avg accuracy: %f. avg loss: %f' % (reward_sum, running_reward, accuracy, loss))\n",
    "                reward_sum = 0\n",
    "                observation = env.reset() # reset env\n",
    "                prev_frame = None\n",
    "                episode_number += 1\n",
    "                \n",
    "                if len(frames) > 0:\n",
    "                    self.save_frames_as_gif(frames, filename = f'tfModelEp{len(running_rewards)}.gif')\n",
    "                    \n",
    "                running_rewards.append(running_reward)\n",
    "\n",
    "                with open(\"DeleteThis.txt\", \"wb\") as fp:   #Pickling\n",
    "                    pickle.dump(running_rewards, fp)\n",
    "                \n",
    "                count = 0\n",
    "                frames = []\n",
    "                ep_rewards = []\n",
    "                \n",
    "                if len(running_rewards) == 6001:\n",
    "                    break\n",
    "\n",
    "            if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n",
    "                print('ep %d: game finished, reward: %f, epsilon: %g' % (episode_number, reward, self.eps) + ('' if reward == -1 else ' !!!!!!!!'))\n",
    "                \n",
    "    def choose_action(self, state):\n",
    "        if np.random.random() < self.eps:\n",
    "            randn = np.random.randint(2, 4)\n",
    "            up_prob = 0\n",
    "            return np.random.randint(2, 4), up_prob\n",
    "        else:\n",
    "            state = state.reshape((1,6400))\n",
    "            up_prob = self.target_model.predict(state)\n",
    "            if up_prob >= .5:\n",
    "                return 2, up_prob\n",
    "            else:\n",
    "                return 3, up_prob\n",
    "    \n",
    "    def discount_rewards(self, rewards):\n",
    "        gamma = 0.99\n",
    "        discounted_r = np.zeros_like(rewards)\n",
    "        running_add = 0\n",
    "        for t in reversed(range(0, rewards.size)):\n",
    "            if rewards[t] != 0: running_add = 0\n",
    "            running_add = running_add * gamma + rewards[t]\n",
    "            discounted_r[t] = running_add\n",
    "        return discounted_r\n",
    "            \n",
    "    def prepro(self, input_frame):\n",
    "        input_frame = input_frame[34:194]\n",
    "        input_frame = input_frame[::2,::2,0]\n",
    "        input_frame[input_frame == 144] = 0 \n",
    "        input_frame[input_frame == 109] = 0 \n",
    "        input_frame[input_frame != 0] = 1 \n",
    "        return input_frame.astype(np.float).ravel()\n",
    "    \n",
    "    def save_frames_as_gif(self, frames, filename):\n",
    "        patch = plt.imshow(frames[0])\n",
    "        plt.axis('off')\n",
    "        def animate(i):\n",
    "            patch.set_data(frames[i])\n",
    "        anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n",
    "        if filename:\n",
    "            anim.save(filename, dpi=72, writer='imagemagick')\n",
    "    \n",
    "    def replay(self, samples):\n",
    "        states = np.array([val[0] for val in samples])\n",
    "        up_probs = np.array([val[1] for val in samples])\n",
    "        rewards = np.array([val[2] for val in samples])\n",
    "        \n",
    "        up_probs = np.vstack(up_probs)\n",
    "        rewards = np.vstack(rewards)\n",
    "            \n",
    "        discount_rewards = self.discount_rewards(rewards)\n",
    "        discount_rewards -= np.mean(discount_rewards)\n",
    "        discount_rewards /= np.std(discount_rewards)\n",
    "        \n",
    "        up_probs = up_probs * discount_rewards\n",
    "        \n",
    "        up_probs = np.asarray(up_probs).astype('float32')\n",
    "        \n",
    "        history = self.model.fit(states, up_probs, batch_size = len(samples), verbose = 0, epochs = 50)\n",
    "        \n",
    "        return np.mean(history.history[\"acc\"]), np.mean(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82070f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: game finished, reward: -1.000000, epsilon: 0.999631\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.999073\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.998857\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.998664\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.998466\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.998245\n",
      "ep 0: game finished, reward: 1.000000, epsilon: 0.997854 !!!!!!!!\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.997444\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.997228\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.997008\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.99681\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.996612\n",
      "ep 0: game finished, reward: 1.000000, epsilon: 0.996216 !!!!!!!!\n",
      "ep 0: game finished, reward: 1.000000, epsilon: 0.995653 !!!!!!!!\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.995266\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.99505\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.994501\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.994272\n",
      "ep 0: game finished, reward: 1.000000, epsilon: 0.993885 !!!!!!!!\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.993507\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.993295\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.993088\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.992886\n",
      "ep 0: game finished, reward: -1.000000, epsilon: 0.992665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-41c530eaec0d>:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  up_probs = np.array([val[1] for val in samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -17.000000. running mean: -17.000000. avg accuracy: 0.492841. avg loss: 0.110026\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.992445\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.991698\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.991486\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.991266\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.991054\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.990852\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.990627\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.990415\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.990208\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.989628\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.989407\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.988822\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.988246\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.988053\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.987832\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.987621\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.987405\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.987202\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.986991\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.986415\n",
      "ep 1: game finished, reward: -1.000000, epsilon: 0.986212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MovieWriter imagemagick unavailable; using Pillow instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.000000. running mean: -17.040000. avg accuracy: 0.478476. avg loss: -0.695349\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.98601\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.985623\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.985411\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.984475\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.984268\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.984057\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.983836\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.983274\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.983067\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.982522\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.982324\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.982135\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.981559\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.981352\n",
      "ep 2: game finished, reward: 1.000000, epsilon: 0.980938 !!!!!!!!\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.980569\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.980358\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.980155\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.979953\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.979732\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.979525\n",
      "ep 2: game finished, reward: -1.000000, epsilon: 0.979309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-34-41c530eaec0d>:145: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  up_probs = np.array([val[1] for val in samples])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -20.000000. running mean: -17.069600. avg accuracy: 0.467966. avg loss: -1.034698\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.979084\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.978702\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.978486\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.978274\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.978072\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.97786\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.977649\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.977451\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.977248\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.977037\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.976479\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.976285\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.976074\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.975867\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.975651\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.975448\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.975223\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.975025\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.974823\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.97462\n",
      "ep 3: game finished, reward: -1.000000, epsilon: 0.974404\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.108904. avg accuracy: 0.491571. avg loss: -2.339420\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.974215\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.973837\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.973626\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.973419\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.973207\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.973018\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.972811\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.972604\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.972388\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.972195\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.971988\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.971776\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.97156\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.97134\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.971137\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.970926\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.970345\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.970143\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.969936\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.969729\n",
      "ep 4: game finished, reward: -1.000000, epsilon: 0.969517\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.147815. avg accuracy: 0.477402. avg loss: -4.251333\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.969297\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.968901\n",
      "ep 5: game finished, reward: 1.000000, epsilon: 0.968122 !!!!!!!!\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.967758\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.967555\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.967344\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.96715\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.966934\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.966732\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.96652\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.966322\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.96612\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.965922\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.965724\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.965148\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.964941\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.964738\n",
      "ep 5: game finished, reward: 1.000000, epsilon: 0.964347 !!!!!!!!\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.963964\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.963757\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.96355\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.96333\n",
      "ep 5: game finished, reward: -1.000000, epsilon: 0.963114\n",
      "resetting env. episode reward total was -19.000000. running mean: -17.166337. avg accuracy: 0.460844. avg loss: -3.642568\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.962902\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.962538\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.962331\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.962106\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.961876\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.961651\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.96144\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.961228\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.961021\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.960823\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.960603\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.960387\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.96018\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.959977\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.95977\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.959545\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.959343\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.959136\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.958564\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.958353\n",
      "ep 6: game finished, reward: -1.000000, epsilon: 0.958141\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.204673. avg accuracy: 0.457448. avg loss: -6.181768\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.95793\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.957534\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.957322\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.957097\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.956539\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.956328\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.956125\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.955918\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.955711\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.955504\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.955297\n",
      "ep 7: game finished, reward: 1.000000, epsilon: 0.954928 !!!!!!!!\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.95455\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.954343\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.954132\n",
      "ep 7: game finished, reward: 1.000000, epsilon: 0.953713 !!!!!!!!\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.953335\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.953142\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.952921\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.952705\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.952503\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.952287\n",
      "ep 7: game finished, reward: -1.000000, epsilon: 0.952084\n",
      "resetting env. episode reward total was -19.000000. running mean: -17.222627. avg accuracy: 0.488333. avg loss: -3.784641\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.951882\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.951112\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.950532\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.95032\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.950113\n",
      "ep 8: game finished, reward: 1.000000, epsilon: 0.949726 !!!!!!!!\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.948979\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.948763\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.948538\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.948331\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.948115\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.947904\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.947701\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.947481\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.947278\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.947067\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.946473\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.946266\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.946059\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.945865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: game finished, reward: -1.000000, epsilon: 0.945658\n",
      "ep 8: game finished, reward: -1.000000, epsilon: 0.94546\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.250400. avg accuracy: 0.470699. avg loss: -4.668743\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.945253\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.944835\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.944628\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.944425\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.944205\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.943998\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.943786\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.943566\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.943359\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.943147\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.942945\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.942747\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.942549\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.942342\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.942135\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.941919\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.941707\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.941505\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.941289\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.941082\n",
      "ep 9: game finished, reward: -1.000000, epsilon: 0.940519\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.287896. avg accuracy: 0.466721. avg loss: -12.736648\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.940312\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.939939\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.939709\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.939507\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.939291\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.939066\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.938863\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.937918\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.937711\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.937495\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.936946\n",
      "ep 10: game finished, reward: 1.000000, epsilon: 0.936555 !!!!!!!!\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.936154\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.935947\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.93538\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.935169\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.934953\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.934746\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.93453\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.934323\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.934111\n",
      "ep 10: game finished, reward: -1.000000, epsilon: 0.933531\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.315017. avg accuracy: 0.482431. avg loss: -7.301422\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.933315\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.932937\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.932739\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.932527\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.931947\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.931375\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.931182\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.930979\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.930754\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.930525\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.930336\n",
      "ep 11: game finished, reward: 1.000000, epsilon: 0.92994 !!!!!!!!\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.929553\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.929359\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.929143\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.928927\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.928347\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.928149\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.927928\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.927744\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.927532\n",
      "ep 11: game finished, reward: -1.000000, epsilon: 0.927325\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.341867. avg accuracy: 0.503041. avg loss: -10.447454\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.9271\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.926709\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.926502\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.926299\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.926092\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.925494\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.925296\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.92508\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.924868\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.924661\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.92445\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.924243\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.924049\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.923464\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.923244\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.923028\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.922821\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.922614\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.922398\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.922191\n",
      "ep 12: game finished, reward: -1.000000, epsilon: 0.921979\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.378449. avg accuracy: 0.487094. avg loss: -17.577386\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.921759\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.921363\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.921156\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.920962\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.920742\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.919392\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.919185\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.918604\n",
      "ep 13: game finished, reward: 1.000000, epsilon: 0.918213 !!!!!!!!\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.917817\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.91761\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.917403\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.9172\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.916998\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.916786\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.916593\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.916363\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.916143\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.915936\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.915729\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.915522\n",
      "ep 13: game finished, reward: -1.000000, epsilon: 0.91531\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.404664. avg accuracy: 0.500987. avg loss: -9.670795\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.915103\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.914721\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.9145\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.914289\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.913708\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.913515\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.913303\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.913092\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.912889\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.912687\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.912462\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.911872\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.911292\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.909991\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.909784\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.909582\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.909379\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.909177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: game finished, reward: -1.000000, epsilon: 0.908965\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.908749\n",
      "ep 14: game finished, reward: -1.000000, epsilon: 0.908551\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.440617. avg accuracy: 0.506658. avg loss: -10.494019\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.908344\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.907575\n",
      "ep 15: game finished, reward: 1.000000, epsilon: 0.907179 !!!!!!!!\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.906796\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.906229\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.906004\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.905797\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.905599\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.90537\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.905172\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.90496\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.904753\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.904528\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.904317\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.903727\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.903516\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.903313\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.903106\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.902877\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.902332\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.902116\n",
      "ep 15: game finished, reward: -1.000000, epsilon: 0.901909\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.466211. avg accuracy: 0.486058. avg loss: -15.769970\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.901689\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.90132\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.901095\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.900883\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.900663\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.90046\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.900235\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.900037\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.899835\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.899614\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.899416\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.899218\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.899016\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.898804\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.898593\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.898381\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.897823\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.897607\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.897382\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.896788\n",
      "ep 16: game finished, reward: -1.000000, epsilon: 0.896581\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.501549. avg accuracy: 0.513181. avg loss: -18.044145\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.89637\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.895992\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.895438\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.895236\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.895033\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.894808\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.894592\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.894021\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.89344\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.893233\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.893017\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.892815\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.892248\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.892027\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.891829\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.891627\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.891415\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.890835\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.89061\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.890403\n",
      "ep 17: game finished, reward: -1.000000, epsilon: 0.8902\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.536534. avg accuracy: 0.546860. avg loss: -18.445253\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.889993\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.889602\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.889399\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.889188\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.888981\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.88876\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.88854\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.887964\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.887757\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.886807\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.886609\n",
      "ep 18: game finished, reward: 1.000000, epsilon: 0.886218 !!!!!!!!\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.885817\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.885606\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.885399\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.885183\n",
      "ep 18: game finished, reward: 1.000000, epsilon: 0.884764 !!!!!!!!\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.884373\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.884161\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.883959\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.883761\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.883549\n",
      "ep 18: game finished, reward: -1.000000, epsilon: 0.883347\n",
      "resetting env. episode reward total was -19.000000. running mean: -17.551168. avg accuracy: 0.518398. avg loss: -19.628543\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.88314\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.882771\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.882555\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.882348\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.882145\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.881929\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.881713\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.881506\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.881299\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.881097\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.880885\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.880669\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.880093\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.8799\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.879346\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.879139\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.878914\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.878698\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.8785\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.878298\n",
      "ep 19: game finished, reward: -1.000000, epsilon: 0.878082\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.585657. avg accuracy: 0.527419. avg loss: -35.516119\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.877875\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.877492\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.877294\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.877087\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.87688\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.876673\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.876457\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.876237\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.876025\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.875827\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.87562\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.875409\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.875224\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.875022\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.874464\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.874261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: game finished, reward: -1.000000, epsilon: 0.874054\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.873852\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.87364\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.873433\n",
      "ep 20: game finished, reward: -1.000000, epsilon: 0.873231\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.619800. avg accuracy: 0.539648. avg loss: -42.046436\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.873015\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.872259\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.87207\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.871863\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.871669\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.871458\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.871251\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.87067\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.870463\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.870256\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.87004\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.869851\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.869653\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.869451\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.869226\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.86901\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.868447\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.867876\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.867655\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.867426\n",
      "ep 21: game finished, reward: -1.000000, epsilon: 0.86721\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.653602. avg accuracy: 0.548542. avg loss: -44.481191\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.866998\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.86662\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.866413\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.866211\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.866013\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.86581\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.865599\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.865387\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.865185\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.864973\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.864762\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.864537\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.86433\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.863758\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.863565\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.863358\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.863142\n",
      "ep 22: game finished, reward: 1.000000, epsilon: 0.86275 !!!!!!!!\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.862372\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.862156\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.86194\n",
      "ep 22: game finished, reward: -1.000000, epsilon: 0.861738\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.677066. avg accuracy: 0.531172. avg loss: -15.948611\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.861126\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.860734\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.859443\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.859236\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.859029\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.858808\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.858601\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.858381\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.858178\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.85798\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.857773\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.857553\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.857341\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.857134\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.856932\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.85672\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.856158\n",
      "ep 23: game finished, reward: 1.000000, epsilon: 0.855744 !!!!!!!!\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.855348\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.855141\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.854929\n",
      "ep 23: game finished, reward: -1.000000, epsilon: 0.854731\n",
      "ep 23: game finished, reward: 1.000000, epsilon: 0.854326 !!!!!!!!\n",
      "resetting env. episode reward total was -19.000000. running mean: -17.690295. avg accuracy: 0.534100. avg loss: -12.754862\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.853575\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.853197\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.85299\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.852774\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.852571\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.852355\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.852153\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.851955\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.851734\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.851509\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.851293\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.851082\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.850866\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.850663\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.850461\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.850267\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.850042\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.849826\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.84961\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.849403\n",
      "ep 24: game finished, reward: -1.000000, epsilon: 0.849201\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.723392. avg accuracy: 0.527335. avg loss: -64.835481\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.848998\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.848607\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.848404\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.848206\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.847999\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.847788\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.847572\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.847347\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.847122\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.846915\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.846352\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.846136\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.84592\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.845709\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.845497\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.845281\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.845092\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.844876\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.84466\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.844449\n",
      "ep 25: game finished, reward: -1.000000, epsilon: 0.844251\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.756159. avg accuracy: 0.575477. avg loss: -61.461064\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.844044\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.843675\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.843463\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.843252\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.84304\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.842833\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.842613\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.842406\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.842208\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.842014\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.841798\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.841582\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.841384\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.841195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: game finished, reward: -1.000000, epsilon: 0.840979\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.840772\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.840565\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.840354\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.839773\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.839557\n",
      "ep 26: game finished, reward: -1.000000, epsilon: 0.83935\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.788597. avg accuracy: 0.538680. avg loss: -64.670770\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.839134\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.838752\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.838522\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.838306\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.83809\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.837901\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.837703\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.837492\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.836925\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.836704\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.836493\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.836281\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.836065\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.835849\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.835633\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.835435\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.835224\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.835021\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.834801\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.834607\n",
      "ep 27: game finished, reward: -1.000000, epsilon: 0.834391\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.820711. avg accuracy: 0.550264. avg loss: -90.592927\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.834189\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.833419\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.833217\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.83301\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.832807\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.832596\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.832384\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.83179\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.831592\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.831372\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.8308\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.830589\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.830373\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.830166\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.829954\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.829747\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.829203\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.828973\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.828762\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.828555\n",
      "ep 28: game finished, reward: -1.000000, epsilon: 0.828348\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.852504. avg accuracy: 0.541044. avg loss: -70.355572\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.828154\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.827776\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.8272\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.826629\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.826431\n",
      "ep 29: game finished, reward: 1.000000, epsilon: 0.826044 !!!!!!!!\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.825648\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.825436\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.825229\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.825018\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.824802\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.824595\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.824388\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.824176\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.823974\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.823758\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.823555\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.823335\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.823132\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.822939\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.822727\n",
      "ep 29: game finished, reward: -1.000000, epsilon: 0.822516\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.873979. avg accuracy: 0.550859. avg loss: -40.000994\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.822286\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.821895\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.821683\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.821467\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.82126\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.821053\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.820833\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.820621\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.820045\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.819838\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.819636\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.81942\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.819204\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.818988\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.81879\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.818578\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.818358\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.818146\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.817944\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.817737\n",
      "ep 30: game finished, reward: -1.000000, epsilon: 0.81753\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.905239. avg accuracy: 0.574169. avg loss: -110.618848\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.817332\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.81694\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.816738\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.816535\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.816319\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.816103\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.815892\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.815667\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.815464\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.815262\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.815059\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.814857\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.814654\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.814447\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.81424\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.814024\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.813813\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.813592\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.813381\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.813183\n",
      "ep 31: game finished, reward: -1.000000, epsilon: 0.812971\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.936187. avg accuracy: 0.556012. avg loss: -104.156180\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.812751\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.812377\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.812161\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.811959\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.811738\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.811527\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.811324\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.811108\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.810888\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.810685\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.810478\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.810271\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.810055\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.809475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: game finished, reward: -1.000000, epsilon: 0.809263\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.809047\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.808827\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.808602\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.80839\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.808179\n",
      "ep 32: game finished, reward: 1.000000, epsilon: 0.807778 !!!!!!!!\n",
      "ep 32: game finished, reward: -1.000000, epsilon: 0.807013\n",
      "resetting env. episode reward total was -20.000000. running mean: -17.956825. avg accuracy: 0.586153. avg loss: -46.346493\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.806797\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.806419\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.806203\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.806001\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.805785\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.805596\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.805375\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.805177\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.804957\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.804741\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.804529\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.804327\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.804115\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.803904\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.803701\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.803485\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.803265\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.803058\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.802828\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.802621\n",
      "ep 33: game finished, reward: -1.000000, epsilon: 0.80241\n",
      "resetting env. episode reward total was -21.000000. running mean: -17.987257. avg accuracy: 0.549980. avg loss: -145.727816\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.802198\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.801816\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.801618\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.801406\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.801195\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.800997\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.800785\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.800569\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.800367\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.799804\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.799588\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.799381\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.79917\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.798949\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.798724\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.798522\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.798301\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.797748\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.797554\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.797352\n",
      "ep 34: game finished, reward: -1.000000, epsilon: 0.79714\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.017384. avg accuracy: 0.558150. avg loss: -51.540261\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.796555\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.796177\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.79597\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.795763\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.795547\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.795345\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.795133\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.794917\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.794706\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.79449\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.794296\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.79408\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.793873\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.793662\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.793446\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.793243\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.793018\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.792802\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.792591\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.792366\n",
      "ep 35: game finished, reward: -1.000000, epsilon: 0.792159\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.047210. avg accuracy: 0.560941. avg loss: -187.839834\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.791965\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.791574\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.791376\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.790777\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.790575\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.790359\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.790147\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.789945\n",
      "ep 36: game finished, reward: 1.000000, epsilon: 0.789562 !!!!!!!!\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.788806\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.788613\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.788406\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.787843\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.787636\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.78742\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.787213\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.787002\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.786795\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.786583\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.786372\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.786156\n",
      "ep 36: game finished, reward: -1.000000, epsilon: 0.785949\n",
      "ep 36: game finished, reward: 1.000000, epsilon: 0.785539 !!!!!!!!\n",
      "resetting env. episode reward total was -19.000000. running mean: -18.056738. avg accuracy: 0.578283. avg loss: -57.320493\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.785152\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.784761\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.784554\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.784342\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.784135\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.783933\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.78373\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.783528\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.783312\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.783096\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.782884\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.782677\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.782479\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.782268\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.782047\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.781476\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.781273\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.781066\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.780859\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.780648\n",
      "ep 37: game finished, reward: -1.000000, epsilon: 0.780418\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.086171. avg accuracy: 0.568065. avg loss: -141.524408\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.780198\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.779793\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.779577\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.77937\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.779167\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.778969\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.778762\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.778546\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.778326\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.778119\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.777898\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.777691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 38: game finished, reward: -1.000000, epsilon: 0.77748\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.777273\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.77707\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.776863\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.776647\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.77644\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.776233\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.776022\n",
      "ep 38: game finished, reward: -1.000000, epsilon: 0.775815\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.115309. avg accuracy: 0.599000. avg loss: -193.901086\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.775608\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.775239\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.775041\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.774829\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.774604\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.774406\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.77419\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.77397\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.773749\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.773542\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.773326\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.773124\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.772921\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.77271\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.772503\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.771927\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.77172\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.771517\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.771301\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.771081\n",
      "ep 39: game finished, reward: 1.000000, epsilon: 0.770685 !!!!!!!!\n",
      "ep 39: game finished, reward: -1.000000, epsilon: 0.770284\n",
      "resetting env. episode reward total was -20.000000. running mean: -18.134156. avg accuracy: 0.578098. avg loss: -76.826611\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.770073\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.769686\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.76947\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.769267\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.76906\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.768858\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.768642\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.768439\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.76825\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.768025\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.767823\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.767607\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.767391\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.767175\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.766968\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.766765\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.766536\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.766338\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.766122\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.76591\n",
      "ep 40: game finished, reward: -1.000000, epsilon: 0.765685\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.162814. avg accuracy: 0.583187. avg loss: -188.824653\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.765469\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.765087\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.764889\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.764677\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.764457\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.764254\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.764047\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.76384\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.763647\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.76344\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.763215\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.763012\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.762801\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.762594\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.762364\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.761779\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.761586\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.761392\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.761181\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.760956\n",
      "ep 41: game finished, reward: -1.000000, epsilon: 0.760753\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.191186. avg accuracy: 0.589808. avg loss: -199.788756\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.760542\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.760164\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.759939\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.759723\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.759498\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.759286\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.759088\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.758886\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.758674\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.758449\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.758233\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.758022\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.75781\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.757608\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.757396\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.757185\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.75696\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.756766\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.756559\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.756339\n",
      "ep 42: game finished, reward: -1.000000, epsilon: 0.756123\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.219274. avg accuracy: 0.583460. avg loss: -212.449414\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.755911\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.75552\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.755304\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.755101\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.754881\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.754674\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.754449\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.754237\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.75403\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.753828\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.753625\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.753414\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.753202\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.752995\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.752788\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.752563\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.752361\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.752158\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.751951\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.75174\n",
      "ep 43: game finished, reward: -1.000000, epsilon: 0.751537\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.247082. avg accuracy: 0.580510. avg loss: -274.912171\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.751326\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.750925\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.750718\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.750507\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.7503\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.750097\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.74989\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.749674\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.74949\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.749287\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.749076\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.748864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 44: game finished, reward: -1.000000, epsilon: 0.748644\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.748423\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.748203\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.747996\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.747793\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.747582\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.747375\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.747154\n",
      "ep 44: game finished, reward: -1.000000, epsilon: 0.746943\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.274611. avg accuracy: 0.583483. avg loss: -230.423718\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.746727\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.746331\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.746119\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.745921\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.745692\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.74548\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.745264\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.745062\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.744841\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.744639\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.744427\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.744234\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.744045\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.743838\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.743617\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.743415\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.743203\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.743005\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.742789\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.742591\n",
      "ep 45: game finished, reward: -1.000000, epsilon: 0.742384\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.301865. avg accuracy: 0.589545. avg loss: -247.420773\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.742182\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.741804\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.741601\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.74139\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.741165\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.740958\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.740755\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.740539\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.740328\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.740125\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.739927\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.739716\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.739513\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.739302\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.739081\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.738874\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.738658\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.738438\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.73824\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.738028\n",
      "ep 46: game finished, reward: -1.000000, epsilon: 0.737817\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.328846. avg accuracy: 0.619112. avg loss: -261.293331\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.737623\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.736894\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.736678\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.73648\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.736264\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.736053\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.735841\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.73563\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.735432\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.735229\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.735013\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.734806\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.734604\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.734397\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.734185\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.73396\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.733758\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.733542\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.733339\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.733119\n",
      "ep 47: game finished, reward: -1.000000, epsilon: 0.732916\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.355558. avg accuracy: 0.572278. avg loss: -219.575904\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.732705\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.7323\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.732084\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.731877\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.731661\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.731454\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.731247\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.731031\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.730819\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.730626\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.730401\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.730198\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.729991\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.729784\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.729564\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.729357\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.729145\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.728938\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.728718\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.728506\n",
      "ep 48: game finished, reward: -1.000000, epsilon: 0.728299\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.382002. avg accuracy: 0.614912. avg loss: -256.427787\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.728088\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.727705\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.727498\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.727296\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.727093\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.726882\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.726675\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.726459\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.726247\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.726036\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.725824\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.725608\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.725388\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.725158\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.724947\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.72474\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.724537\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.72433\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.72411\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.723894\n",
      "ep 49: game finished, reward: -1.000000, epsilon: 0.723678\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.408182. avg accuracy: 0.606362. avg loss: -273.375145\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.723462\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.722715\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.722508\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.722314\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.722094\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.721887\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.721684\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.721468\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.721275\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.721072\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.720852\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.720645\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.720442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 50: game finished, reward: -1.000000, epsilon: 0.720231\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.720024\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.719817\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.719601\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.719403\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.7192\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.718993\n",
      "ep 50: game finished, reward: -1.000000, epsilon: 0.718777\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.434100. avg accuracy: 0.603526. avg loss: -234.206713\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.718561\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.718197\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.717981\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.717769\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.71754\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.71731\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.717099\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.716874\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.716653\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.716451\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.716239\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.716028\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.715821\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.7156\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.715375\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.715159\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.714939\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.713985\n",
      "ep 51: game finished, reward: 1.000000, epsilon: 0.713607 !!!!!!!!\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.712864\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.712302\n",
      "ep 51: game finished, reward: -1.000000, epsilon: 0.712095\n",
      "resetting env. episode reward total was -20.000000. running mean: -18.449759. avg accuracy: 0.624943. avg loss: -58.783230\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.711879\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.711492\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.711303\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.711087\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.710884\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.710677\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.710457\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.710259\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.710047\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.709836\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.709624\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.709431\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.709201\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.708999\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.708792\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.708589\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.708382\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.708157\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.707946\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.707743\n",
      "ep 52: game finished, reward: -1.000000, epsilon: 0.707532\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.475262. avg accuracy: 0.603984. avg loss: -269.999805\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.707316\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.706947\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.706731\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.706533\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.706326\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.706105\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.705894\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.705678\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.705475\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.705259\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.705048\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.704841\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.704638\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.704409\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.704184\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.703986\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.70377\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.703549\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.703338\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.703122\n",
      "ep 53: game finished, reward: -1.000000, epsilon: 0.702924\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.500509. avg accuracy: 0.603739. avg loss: -356.672012\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.702694\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.702298\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.702091\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.701875\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.701655\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.701443\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.701236\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.701025\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.700813\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.700611\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.700372\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.700161\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.69994\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.699738\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.699517\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.69931\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.699103\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.698887\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.698676\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.698446\n",
      "ep 54: game finished, reward: -1.000000, epsilon: 0.698244\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.525504. avg accuracy: 0.606292. avg loss: -350.683666\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.698046\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.697663\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.697456\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.697227\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.697011\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.696804\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.696583\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.696367\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.696138\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.695922\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.695724\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.695512\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.69531\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.695103\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.694891\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.694666\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.694455\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.694243\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.694023\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.693811\n",
      "ep 55: game finished, reward: -1.000000, epsilon: 0.6936\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.550249. avg accuracy: 0.604255. avg loss: -378.866688\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.693393\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.693006\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.69279\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.692569\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.692353\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.692151\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.691939\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.691737\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.691539\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.691332\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.691111\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.690895\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.69067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 56: game finished, reward: -1.000000, epsilon: 0.69045\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.690229\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.689658\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.689451\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.689248\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.688681\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.688465\n",
      "ep 56: game finished, reward: -1.000000, epsilon: 0.688249\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.574746. avg accuracy: 0.630285. avg loss: -235.646984\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.688029\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.687655\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.687448\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.687241\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.687039\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.686845\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.686634\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.686427\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.686215\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.686004\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.685788\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.68559\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.685392\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.685185\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.684982\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.684766\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.684564\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.684361\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.684145\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.683934\n",
      "ep 57: game finished, reward: -1.000000, epsilon: 0.683722\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.598999. avg accuracy: 0.633746. avg loss: -394.874818\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.683524\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.683128\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.682912\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.682692\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.682467\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.682264\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.682053\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.681832\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.681616\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.681409\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.681207\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.681004\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.680793\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.680586\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.680379\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.680181\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.679978\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.679762\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.67956\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.679339\n",
      "ep 58: game finished, reward: -1.000000, epsilon: 0.67915\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.623009. avg accuracy: 0.624464. avg loss: -429.620294\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.678948\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.678579\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.678367\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.67816\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.677944\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.677737\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.677526\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.677314\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.677094\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.676887\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.67668\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.676468\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.676279\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.676072\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.67587\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.675658\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.675447\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.675235\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.675037\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.67483\n",
      "ep 59: game finished, reward: -1.000000, epsilon: 0.674637\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.646779. avg accuracy: 0.612724. avg loss: -356.586506\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.674421\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.674052\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.673845\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.673633\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.673413\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.67321\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.673003\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.672787\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.67258\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.672369\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.672157\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.671937\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.671739\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.671536\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.67132\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.671109\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.670888\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.670672\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.670447\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.670231\n",
      "ep 60: game finished, reward: -1.000000, epsilon: 0.67002\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.670311. avg accuracy: 0.623151. avg loss: -412.621827\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.669822\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.66943\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.66921\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.668994\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.668787\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.668571\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.668355\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.668143\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.667932\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.66772\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.667518\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.667315\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.667099\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.666892\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.666681\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.666478\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.666262\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.666051\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.665844\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.665646\n",
      "ep 61: game finished, reward: -1.000000, epsilon: 0.66543\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.693608. avg accuracy: 0.584614. avg loss: -468.511084\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.665218\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.664822\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.664611\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.664408\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.664192\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.663976\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.663774\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.663562\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.663364\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.663162\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.662955\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.662743\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.662523\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.662325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 62: game finished, reward: -1.000000, epsilon: 0.6621\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.661897\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.661695\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.661483\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.661281\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.661069\n",
      "ep 62: game finished, reward: -1.000000, epsilon: 0.660867\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.716672. avg accuracy: 0.619565. avg loss: -431.229106\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.660664\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.660277\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.660066\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.659854\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.659629\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.659436\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.65922\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.659022\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.658819\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.658621\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.658401\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.658203\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.658\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.657802\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.657582\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.65737\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.657154\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.656956\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.656758\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.656547\n",
      "ep 63: game finished, reward: -1.000000, epsilon: 0.656349\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.739505. avg accuracy: 0.604801. avg loss: -375.051193\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.656146\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.65575\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.65553\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.655291\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.655089\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.654873\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.654661\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.65445\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.654243\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.654018\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.653811\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.653595\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.653374\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.653154\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.652929\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.652735\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.652519\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.652303\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.652101\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.65188\n",
      "ep 64: game finished, reward: -1.000000, epsilon: 0.651687\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.762110. avg accuracy: 0.633840. avg loss: -381.598149\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.651471\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.65107\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.650863\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.650656\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.650431\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.650233\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.650017\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.649806\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.649603\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.649401\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.649194\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.648987\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.648775\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.648577\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.648366\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.648172\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.64797\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.647745\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.647533\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.647331\n",
      "ep 65: game finished, reward: -1.000000, epsilon: 0.647106\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.784489. avg accuracy: 0.645240. avg loss: -608.769899\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.646885\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.646489\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.646291\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.64608\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.645864\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.645648\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.645436\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.645216\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.645018\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.644802\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.644599\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.644392\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.644181\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.643965\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.643753\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.643551\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.643339\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.643132\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.64293\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.642732\n",
      "ep 66: game finished, reward: -1.000000, epsilon: 0.64252\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.806644. avg accuracy: 0.658540. avg loss: -512.994533\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.642322\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.641931\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.64171\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.641499\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.641292\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.64108\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.640891\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.64068\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.640464\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.64027\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.640059\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.639852\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.639631\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.639415\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.639195\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.638988\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.638776\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.63856\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.638349\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.638142\n",
      "ep 67: game finished, reward: -1.000000, epsilon: 0.637921\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.828578. avg accuracy: 0.642051. avg loss: -611.757598\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.637714\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.637327\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.637116\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.636904\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.636697\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.636481\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.636265\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.636058\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.635865\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.635653\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.635442\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.63523\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.635005\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.634785\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.634569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 68: game finished, reward: -1.000000, epsilon: 0.634353\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.634141\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.633934\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.633723\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.633525\n",
      "ep 68: game finished, reward: -1.000000, epsilon: 0.633309\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.850292. avg accuracy: 0.647342. avg loss: -543.751262\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.633093\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.632679\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.632476\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.632265\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.632049\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.631842\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.631635\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.631432\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.631216\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.631018\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.63082\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.630604\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.630393\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.630172\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.629952\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.629731\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.629533\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.629322\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.629119\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.628903\n",
      "ep 69: game finished, reward: -1.000000, epsilon: 0.628678\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.871789. avg accuracy: 0.663813. avg loss: -610.410199\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.628467\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.628057\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.627864\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.627661\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.627459\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.627252\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.62704\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.626824\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.626617\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.62641\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.626199\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.625992\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.625785\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.625569\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.625357\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.625141\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.624943\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.624723\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.624516\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.624313\n",
      "ep 70: game finished, reward: -1.000000, epsilon: 0.624111\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.893071. avg accuracy: 0.652177. avg loss: -493.072071\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.623899\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.623521\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.62331\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.623089\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.622873\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.62268\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.622468\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.622261\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.622045\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.621843\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.621627\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.621406\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.621208\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.62101\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.620799\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.620578\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.620358\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.620133\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.619926\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.619723\n",
      "ep 71: game finished, reward: -1.000000, epsilon: 0.619503\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.914140. avg accuracy: 0.660818. avg loss: -426.226602\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.619278\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.618886\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.61867\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.618477\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.618279\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.618076\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.617856\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.617649\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.617433\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.61723\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.617028\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.616825\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.616636\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.61642\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.616209\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.615993\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.615781\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.615574\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.615349\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.615142\n",
      "ep 72: game finished, reward: -1.000000, epsilon: 0.614931\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.934999. avg accuracy: 0.636568. avg loss: -695.324315\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.614715\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.614328\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.614121\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.613918\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.613684\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.613473\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.613252\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.613045\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.612847\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.612636\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.612415\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.612204\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.611983\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.611767\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.611556\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.611358\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.611151\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.610935\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.610732\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.61053\n",
      "ep 73: game finished, reward: -1.000000, epsilon: 0.610323\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.955649. avg accuracy: 0.657009. avg loss: -686.429186\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.610111\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.609733\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.609504\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.609292\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.609076\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.60886\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.60864\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.608437\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.608226\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.60801\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.607794\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.607587\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.607371\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.607164\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.606961\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.606754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 74: game finished, reward: -1.000000, epsilon: 0.606534\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.606322\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.606115\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.605899\n",
      "ep 74: game finished, reward: -1.000000, epsilon: 0.605692\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.976092. avg accuracy: 0.636023. avg loss: -536.814651\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.605494\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.605125\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.604918\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.604707\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.604495\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.604261\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.604054\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.603838\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.603622\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.603402\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.603186\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.602983\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.602776\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.602574\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.602358\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.602151\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.601962\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.601759\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.601557\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.601345\n",
      "ep 75: game finished, reward: -1.000000, epsilon: 0.601134\n",
      "resetting env. episode reward total was -21.000000. running mean: -18.996331. avg accuracy: 0.647704. avg loss: -568.363362\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.600927\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.600522\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.600292\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.600067\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.599851\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.599649\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.599437\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.599235\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.599032\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.59883\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.598623\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.598416\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.598204\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.598006\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.597804\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.597592\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.597399\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.597183\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.596971\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.596769\n",
      "ep 76: game finished, reward: -1.000000, epsilon: 0.596562\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.016368. avg accuracy: 0.661816. avg loss: -598.412134\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.596368\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.595977\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.595756\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.59554\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.595324\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.595117\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.59491\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.59469\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.594478\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.594258\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.594042\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.593844\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.593641\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.593425\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.593227\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.593025\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.592818\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.592611\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.592395\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.592188\n",
      "ep 77: game finished, reward: -1.000000, epsilon: 0.591976\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.036204. avg accuracy: 0.643027. avg loss: -736.883560\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.59176\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.591396\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.591184\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.590968\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.590757\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.590559\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.590352\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.590131\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.589929\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.589717\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.58951\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.589299\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.589092\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.588898\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.588687\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.588489\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.588286\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.588088\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.58789\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.58767\n",
      "ep 78: game finished, reward: -1.000000, epsilon: 0.587458\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.055842. avg accuracy: 0.672498. avg loss: -519.931537\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.587238\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.586864\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.586653\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.586441\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.586239\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.586032\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.585825\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.585622\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.585415\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.585199\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.584997\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.58479\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.584574\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.584362\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.584164\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.583957\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.583746\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.583539\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.583332\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.583129\n",
      "ep 79: game finished, reward: -1.000000, epsilon: 0.58294\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.075284. avg accuracy: 0.666547. avg loss: -700.139310\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.582729\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.582351\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.582148\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.581937\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.581712\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.581496\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.581284\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.581086\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.580879\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.580677\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.580474\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.580254\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.580042\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.579826\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.579597\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.579399\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.579196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 80: game finished, reward: -1.000000, epsilon: 0.578998\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.578796\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.578584\n",
      "ep 80: game finished, reward: -1.000000, epsilon: 0.578368\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.094531. avg accuracy: 0.662849. avg loss: -833.918441\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.578148\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.577761\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.577549\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.577329\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.577122\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.57691\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.576712\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.576519\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.576316\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.576123\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.575911\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.575718\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.575502\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.575295\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.575092\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.574885\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.574678\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.574476\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.574264\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.574048\n",
      "ep 81: game finished, reward: -1.000000, epsilon: 0.573832\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.113586. avg accuracy: 0.669176. avg loss: -493.188070\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.573616\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.57322\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.573022\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.572806\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.572595\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.572388\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.572172\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.57196\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.571731\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.571524\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.571317\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.571114\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.570885\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.570678\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.570462\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.57025\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.570048\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.569836\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.56962\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.569418\n",
      "ep 82: game finished, reward: -1.000000, epsilon: 0.569197\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.132450. avg accuracy: 0.660466. avg loss: -713.090198\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.568981\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.568603\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.568396\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.568194\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.568\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.567762\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.567546\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.567334\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.567127\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.566929\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.566718\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.566497\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.566286\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.566074\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.565863\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.565647\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.56544\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.565242\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.565008\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.564787\n",
      "ep 83: game finished, reward: -1.000000, epsilon: 0.564589\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.151126. avg accuracy: 0.677691. avg loss: -635.666686\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.564382\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.564\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.563793\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.563586\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.563374\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.563172\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.562956\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.562744\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.562524\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.562321\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.562105\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.561898\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.561687\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.561466\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.561268\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.561048\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.560845\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.560629\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.560409\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.560193\n",
      "ep 84: game finished, reward: -1.000000, epsilon: 0.559986\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.169614. avg accuracy: 0.675753. avg loss: -612.383218\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.559783\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.559392\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.559185\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.558964\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.558757\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.558528\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.55833\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.558123\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.557916\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.557704\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.557484\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.55729\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.557088\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.556876\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.556669\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.556467\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.556237\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.556021\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.555801\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.555585\n",
      "ep 85: game finished, reward: -1.000000, epsilon: 0.555364\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.187918. avg accuracy: 0.675500. avg loss: -619.136260\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.555144\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.554766\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.554568\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.554361\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.554154\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.553951\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.55374\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.553528\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.553317\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.553096\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.552876\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.552655\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.552444\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.552237\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.552034\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.551809\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.551598\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.551386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 86: game finished, reward: -1.000000, epsilon: 0.551166\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.550954\n",
      "ep 86: game finished, reward: -1.000000, epsilon: 0.550747\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.206039. avg accuracy: 0.693184. avg loss: -730.416904\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.550536\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.550162\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.549951\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.549744\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.549532\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.549325\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.549114\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.548893\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.548691\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.548484\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.548281\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.548074\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.547858\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.547633\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.547426\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.547224\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.547012\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.54681\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.546598\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.546387\n",
      "ep 87: game finished, reward: -1.000000, epsilon: 0.546171\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.223979. avg accuracy: 0.671476. avg loss: -861.114038\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.545964\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.545577\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.54537\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.545158\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.544947\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.54474\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.544524\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.544312\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.544101\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.543903\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.543678\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.543471\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.543268\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.543048\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.542845\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.542643\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.54244\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.542224\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.542008\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.541788\n",
      "ep 88: game finished, reward: -1.000000, epsilon: 0.541585\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.241739. avg accuracy: 0.688723. avg loss: -630.248131\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.541383\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.541\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.540789\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.540573\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.540361\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.540145\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.539952\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.539763\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.53956\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.539353\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.539146\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.538944\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.538737\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.538525\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.538327\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.538107\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.537895\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.537688\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.537481\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.537274\n",
      "ep 89: game finished, reward: -1.000000, epsilon: 0.537067\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.259321. avg accuracy: 0.683456. avg loss: -740.415586\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.536851\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.536455\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.536262\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.536055\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.535843\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.535614\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.535416\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.535195\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.534988\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.534795\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.534579\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.534372\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.534151\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.533944\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.533746\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.533539\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.533319\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.533107\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.532887\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.532675\n",
      "ep 90: game finished, reward: -1.000000, epsilon: 0.532477\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.276728. avg accuracy: 0.686502. avg loss: -733.021865\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.532284\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.531888\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.531681\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.531483\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.531276\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.53106\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.530857\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.530659\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.530434\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.530214\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.53002\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.529818\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.529611\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.529395\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.529188\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.528976\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.528774\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.528544\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.528337\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.528126\n",
      "ep 91: game finished, reward: -1.000000, epsilon: 0.527923\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.293961. avg accuracy: 0.691061. avg loss: -770.454677\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.527703\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.52732\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.527104\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.526897\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.526704\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.526492\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.526294\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.526087\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.525876\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.525655\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.525439\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.525223\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.525021\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.524805\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.524607\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.524391\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.524179\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.523968\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.523747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 92: game finished, reward: -1.000000, epsilon: 0.52354\n",
      "ep 92: game finished, reward: -1.000000, epsilon: 0.523324\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.311021. avg accuracy: 0.713183. avg loss: -753.921396\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.523122\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.522735\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.522546\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.522325\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.522114\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.521907\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.521686\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.521475\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.521272\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.521052\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.520849\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.520647\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.520435\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.520228\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.520021\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.519814\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.519607\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.519396\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.519189\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.518982\n",
      "ep 93: game finished, reward: -1.000000, epsilon: 0.518766\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.327911. avg accuracy: 0.686384. avg loss: -743.247380\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.518554\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.518172\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.517956\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.517731\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.517519\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.517312\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.51711\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.516903\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.516696\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.516484\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.516277\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.516057\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.515872\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.51567\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.515467\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.515256\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.515049\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.514855\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.514648\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.514441\n",
      "ep 94: game finished, reward: -1.000000, epsilon: 0.514234\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.344632. avg accuracy: 0.690249. avg loss: -667.319396\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.514032\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.513649\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.513456\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.513249\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.513051\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.512844\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.512637\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.51243\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.512205\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.512002\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.511804\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.511606\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.511404\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.511192\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.510994\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.510792\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.510576\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.510373\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.510157\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.509932\n",
      "ep 95: game finished, reward: -1.000000, epsilon: 0.509725\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.361186. avg accuracy: 0.710739. avg loss: -1026.003079\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.509523\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.509149\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.508938\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.508717\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.508501\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.508294\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.508083\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.507862\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.50766\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.507444\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.507232\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.50703\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.506832\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.506611\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.506413\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.506206\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.506008\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.505792\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.50559\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.505383\n",
      "ep 96: game finished, reward: -1.000000, epsilon: 0.505176\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.377574. avg accuracy: 0.732544. avg loss: -798.550038\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.50496\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.504568\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.504366\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.504136\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.503907\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.503682\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.503484\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.503281\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.503074\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.502867\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.502647\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.502431\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.502206\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.502003\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.501801\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.501589\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.501373\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.501157\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.500959\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.500757\n",
      "ep 97: game finished, reward: -1.000000, epsilon: 0.500541\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.393798. avg accuracy: 0.725606. avg loss: -763.775923\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.50032\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.499956\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.49974\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.499533\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.499321\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.499114\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.498907\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.498714\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.49852\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.498313\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.498093\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.497886\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.497674\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.497458\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.497242\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.497035\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.496833\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.496635\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.496419\n",
      "ep 98: game finished, reward: -1.000000, epsilon: 0.496212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 98: game finished, reward: -1.000000, epsilon: 0.496\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.409860. avg accuracy: 0.738810. avg loss: -522.011444\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.495784\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.495393\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.495181\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.494974\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.494758\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.494533\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.494317\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.49411\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.493903\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.493696\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.493498\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.493287\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.493075\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.492873\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.492666\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.492463\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.492261\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.492049\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.491833\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.491613\n",
      "ep 99: game finished, reward: -1.000000, epsilon: 0.491406\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.425761. avg accuracy: 0.699706. avg loss: -947.539612\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.491194\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.490812\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.490596\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.490389\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.490168\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.489952\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.489741\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.489529\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.489322\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.489115\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.488908\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.488692\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.488481\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.48826\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.488049\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.487842\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.487635\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.487432\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.487225\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.487005\n",
      "ep 100: game finished, reward: -1.000000, epsilon: 0.486793\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.441504. avg accuracy: 0.712850. avg loss: -857.127212\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.4866\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.486235\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.486024\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.485826\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.485596\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.485389\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.485173\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.484966\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.48475\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.484539\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.484332\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.484138\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.483918\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.483711\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.483499\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.483283\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.483076\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.482869\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.482653\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.482442\n",
      "ep 101: game finished, reward: -1.000000, epsilon: 0.48223\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.457089. avg accuracy: 0.728039. avg loss: -662.881156\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.48201\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.481641\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.481434\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.481204\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.480997\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.480786\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.480579\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.480376\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.480165\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.479949\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.479728\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.479508\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.479287\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.479089\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.478887\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.478662\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.478441\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.478239\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.478036\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.477811\n",
      "ep 102: game finished, reward: -1.000000, epsilon: 0.477591\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.472518. avg accuracy: 0.706265. avg loss: -1051.002483\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.477384\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.477015\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.476808\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.476583\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.476371\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.476155\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.475944\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.475737\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.475534\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.475327\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.475134\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.47494\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.474733\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.474526\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.474319\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.474108\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.47391\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.473698\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.473482\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.473271\n",
      "ep 103: game finished, reward: -1.000000, epsilon: 0.473055\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.487793. avg accuracy: 0.740415. avg loss: -833.786960\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.472834\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.472456\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.472254\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.472033\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.471826\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.471619\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.471403\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.471183\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.470976\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.470764\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.47053\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.470328\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.470112\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.469891\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.469666\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.469428\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.469216\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.469005\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.46878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 104: game finished, reward: -1.000000, epsilon: 0.468573\n",
      "ep 104: game finished, reward: -1.000000, epsilon: 0.468352\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.502915. avg accuracy: 0.726846. avg loss: -917.650313\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.468154\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.467763\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.467547\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.467331\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.467106\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.466899\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.466683\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.466462\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.46626\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.466066\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.465855\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.465643\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.465454\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.465247\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.465018\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.464797\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.464595\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.464397\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.46419\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.463974\n",
      "ep 105: game finished, reward: -1.000000, epsilon: 0.463767\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.517886. avg accuracy: 0.699161. avg loss: -922.760829\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.463542\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.463159\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.462948\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.462732\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.462516\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.4623\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.462088\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.461877\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.461661\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.461449\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.461238\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.46104\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.460819\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.460612\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.460396\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.460189\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.459973\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.459771\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.459559\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.459361\n",
      "ep 106: game finished, reward: -1.000000, epsilon: 0.459163\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.532707. avg accuracy: 0.739393. avg loss: -800.936556\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.458947\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.458578\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.458362\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.458164\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.457953\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.457764\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.457548\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.45735\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.457138\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.456922\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.456711\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.456495\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.456279\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.456049\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.455838\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.455626\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.455419\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.455217\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.455014\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.454807\n",
      "ep 107: game finished, reward: -1.000000, epsilon: 0.454596\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.547380. avg accuracy: 0.717072. avg loss: -798.419974\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.454398\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.454006\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.453804\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.453588\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.453381\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.453187\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.452976\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.45276\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.452539\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.452323\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.452125\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.4519\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.451684\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.451477\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.451261\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.451045\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.450829\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.450627\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.450411\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.450222\n",
      "ep 108: game finished, reward: -1.000000, epsilon: 0.450006\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.561906. avg accuracy: 0.738513. avg loss: -732.071099\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.449799\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.449421\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.4492\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.448975\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.448777\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.448566\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.448354\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.448143\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.447922\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.44772\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.447517\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.447301\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.447094\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.446892\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.446671\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.446464\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.446262\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.446064\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.445852\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.445627\n",
      "ep 109: game finished, reward: -1.000000, epsilon: 0.44542\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.576287. avg accuracy: 0.750580. avg loss: -953.583948\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.445222\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.44484\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.444624\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.444417\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.444201\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.444003\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.4438\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.443598\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.4434\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.443193\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.442977\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.44277\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.442567\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.44236\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.442153\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.441946\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.441721\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.44151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 110: game finished, reward: -1.000000, epsilon: 0.441312\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.441087\n",
      "ep 110: game finished, reward: -1.000000, epsilon: 0.440889\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.590524. avg accuracy: 0.760000. avg loss: -974.904884\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.440668\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.440268\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.440047\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.439845\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.439638\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.439435\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.439219\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.439021\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.438801\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.43858\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.438373\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.438157\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.43795\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.437739\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.437541\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.43732\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.437118\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.436929\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.436717\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.436497\n",
      "ep 111: game finished, reward: -1.000000, epsilon: 0.436281\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.604619. avg accuracy: 0.708934. avg loss: -906.831442\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.436065\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.435664\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.435457\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.43525\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.435034\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.434827\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.434629\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.434427\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.434229\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.434022\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.433828\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.433617\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.433423\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.433194\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.432996\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.432775\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.432568\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.432357\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.432132\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.431929\n",
      "ep 112: game finished, reward: -1.000000, epsilon: 0.4317\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.618573. avg accuracy: 0.742616. avg loss: -851.439042\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.431488\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.431088\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.430867\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.430674\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.430476\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.430273\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.430057\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.429837\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.429603\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.429391\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.429175\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.428977\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.428779\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.428572\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.42837\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.428149\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.427938\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.427735\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.42751\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.42729\n",
      "ep 113: game finished, reward: -1.000000, epsilon: 0.427087\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.632387. avg accuracy: 0.742420. avg loss: -960.607605\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.426876\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.426484\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.426273\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.426048\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.425841\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.425643\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.425445\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.425238\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.425026\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.424819\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.424612\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.424405\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.424194\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.423987\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.423784\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.423568\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.423352\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.423159\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.422956\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.422745\n",
      "ep 114: game finished, reward: -1.000000, epsilon: 0.422542\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.646063. avg accuracy: 0.763539. avg loss: -826.999634\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.422349\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.421971\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.421786\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.421575\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.421354\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.421138\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.420936\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.420747\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.42054\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.420324\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.420108\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.419919\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.419721\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.419518\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.419302\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.419104\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.418902\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.418686\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.41847\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.418272\n",
      "ep 115: game finished, reward: -1.000000, epsilon: 0.418056\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.659602. avg accuracy: 0.760618. avg loss: -862.139142\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.417831\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.417439\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.417228\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.41703\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.416814\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.416607\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.416404\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.416202\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.41599\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.415792\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.41559\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.415369\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.415153\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.414951\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.414739\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.414541\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.414321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 116: game finished, reward: -1.000000, epsilon: 0.414114\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.413902\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.413677\n",
      "ep 116: game finished, reward: -1.000000, epsilon: 0.413475\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.673006. avg accuracy: 0.759626. avg loss: -680.098756\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.413263\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.412885\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.412687\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.412471\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.412255\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.41203\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.411832\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.411621\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.411409\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.411171\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.410964\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.410766\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.41055\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.410338\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.410127\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.409929\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.409735\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.409524\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.409312\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.409119\n",
      "ep 117: game finished, reward: -1.000000, epsilon: 0.408898\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.686276. avg accuracy: 0.751347. avg loss: -908.515166\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.408687\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.408291\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.408075\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.407863\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.407643\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.40744\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.407233\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.407013\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.40681\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.406617\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.406401\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.406198\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.405991\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.40578\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.405577\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.405366\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.405163\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.404961\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.40474\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.404524\n",
      "ep 118: game finished, reward: -1.000000, epsilon: 0.404317\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.699414. avg accuracy: 0.762863. avg loss: -853.395511\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.404097\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.40371\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.403489\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.403282\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.403066\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.402859\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.402661\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.40245\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.402252\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.402036\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.401815\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.401608\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.401406\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.40119\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.400992\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.400785\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.400573\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.400357\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.400141\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.399916\n",
      "ep 119: game finished, reward: -1.000000, epsilon: 0.399718\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.712419. avg accuracy: 0.777191. avg loss: -929.937720\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.399516\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.39912\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.398904\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.398692\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.398481\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.398247\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.398017\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.397801\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.39759\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.397387\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.397194\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.396982\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.396775\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.396573\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.396379\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.396154\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.395929\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.395713\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.395502\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.395304\n",
      "ep 120: game finished, reward: -1.000000, epsilon: 0.395074\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.725295. avg accuracy: 0.748143. avg loss: -838.210043\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.394863\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.394489\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.394282\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.394075\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.393864\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.393657\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.393454\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.393256\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.393045\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.392824\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.392595\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.392374\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.392167\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.391951\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.391744\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.391533\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.391326\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.391119\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.390903\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.390709\n",
      "ep 121: game finished, reward: -1.000000, epsilon: 0.390516\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.738042. avg accuracy: 0.778144. avg loss: -861.458877\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.390304\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.389917\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.389724\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.389512\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.389287\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.389067\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.388855\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.388644\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.388428\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.388216\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.388\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.387784\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.387559\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.387348\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.387141\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.386925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 122: game finished, reward: -1.000000, epsilon: 0.386718\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.386506\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.38629\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.38607\n",
      "ep 122: game finished, reward: -1.000000, epsilon: 0.385863\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.750662. avg accuracy: 0.765237. avg loss: -754.944910\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.385647\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.385251\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.385035\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.384819\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.384612\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.384396\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.38418\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.383959\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.383743\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.383532\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.383325\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.383104\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.382893\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.38269\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.382452\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.38224\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.382024\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.381808\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.381588\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.381381\n",
      "ep 123: game finished, reward: -1.000000, epsilon: 0.381174\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.763155. avg accuracy: 0.768703. avg loss: -1005.087444\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.380962\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.38058\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.380377\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.38017\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.379959\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.379743\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.379531\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.379315\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.379095\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.378888\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.378672\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.37846\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.378235\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.378037\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.377821\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.377605\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.377394\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.377196\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.376998\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.376782\n",
      "ep 124: game finished, reward: -1.000000, epsilon: 0.376588\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.775524. avg accuracy: 0.784838. avg loss: -904.986560\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.376368\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.375967\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.375742\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.37554\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.375328\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.375121\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.374914\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.374698\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.374496\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.374284\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.374055\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.373857\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.373636\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.373429\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.373213\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.373006\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.37279\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.372583\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.372385\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.372174\n",
      "ep 125: game finished, reward: -1.000000, epsilon: 0.371958\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.787768. avg accuracy: 0.766693. avg loss: -1217.854160\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.371742\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.371346\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.371125\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.370918\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.370716\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.3705\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.370288\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.370072\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.369856\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.36964\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.369424\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.369226\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.36901\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.368794\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.368587\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.368376\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.368169\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.367962\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.36775\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.367539\n",
      "ep 126: game finished, reward: -1.000000, epsilon: 0.367327\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.799891. avg accuracy: 0.786433. avg loss: -845.934089\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.367111\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.366706\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.366499\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.366297\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.366103\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.365883\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.365676\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.365469\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.365248\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.36505\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.364843\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.364636\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.364429\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.364222\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.364029\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.363817\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.363601\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.363394\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.363183\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.362976\n",
      "ep 127: game finished, reward: -1.000000, epsilon: 0.362778\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.811892. avg accuracy: 0.775074. avg loss: -1005.420383\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.362562\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.36217\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.361963\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.361743\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.361536\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.361329\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.361126\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.360915\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.360694\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.360496\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.360298\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.360082\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.359871\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.359655\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.359443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 128: game finished, reward: -1.000000, epsilon: 0.359245\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.359047\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.35884\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.358624\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.358422\n",
      "ep 128: game finished, reward: -1.000000, epsilon: 0.35821\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.823773. avg accuracy: 0.775163. avg loss: -1025.883439\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.358003\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.357625\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.357414\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.357207\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.356995\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.356793\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.356572\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.356374\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.356163\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.355956\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.355744\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.355528\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.355308\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.355101\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.354889\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.354682\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.354462\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.354259\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.354043\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.353827\n",
      "ep 129: game finished, reward: -1.000000, epsilon: 0.353616\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.835535. avg accuracy: 0.788683. avg loss: -660.121029\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.353391\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.352999\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.352792\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.352594\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.352383\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.352176\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.351969\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.351766\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.351555\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.351352\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.351132\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.35092\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.350713\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.350511\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.350308\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.350092\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.349872\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.34966\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.349453\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.349251\n",
      "ep 130: game finished, reward: -1.000000, epsilon: 0.349039\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.847180. avg accuracy: 0.812512. avg loss: -877.868881\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.348823\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.348441\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.348229\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.348027\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.347806\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.347604\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.347388\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.347181\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.346965\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.346744\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.346519\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.346317\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.346105\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.345894\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.345673\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.345462\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.345255\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.345043\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.344836\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.344634\n",
      "ep 131: game finished, reward: -1.000000, epsilon: 0.344413\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.858708. avg accuracy: 0.770516. avg loss: -1120.290107\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.344202\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.343819\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.343603\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.343387\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.343167\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.34296\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.342748\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.342537\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.342316\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.342105\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.341884\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.341673\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.341461\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.341245\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.341034\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.340818\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.340597\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.340386\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.34017\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.339963\n",
      "ep 132: game finished, reward: -1.000000, epsilon: 0.339751\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.870121. avg accuracy: 0.772958. avg loss: -1233.657114\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.339562\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.339193\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.338982\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.338788\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.338586\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.338383\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.338176\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.33796\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.337758\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.337546\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.337339\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.337123\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.336925\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.336709\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.336489\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.336273\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.336066\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.335854\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.335638\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.335427\n",
      "ep 133: game finished, reward: -1.000000, epsilon: 0.335206\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.881420. avg accuracy: 0.802950. avg loss: -903.097863\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.334986\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.33459\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.334383\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.334149\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.333951\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.333735\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.333532\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.333303\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.333078\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.332844\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.332646\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.33243\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.332232\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.332025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 134: game finished, reward: -1.000000, epsilon: 0.331827\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.331624\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.331413\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.331215\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.331003\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.330792\n",
      "ep 134: game finished, reward: -1.000000, epsilon: 0.33058\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.892606. avg accuracy: 0.790391. avg loss: -1062.447874\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.330378\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.329977\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.329779\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.329563\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.329334\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.329122\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.328911\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.328695\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.328497\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.328276\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.328056\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.327853\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.327642\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.327426\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.327232\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.327043\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.326823\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.326625\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.326418\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.326197\n",
      "ep 135: game finished, reward: -1.000000, epsilon: 0.32599\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.903679. avg accuracy: 0.782796. avg loss: -1250.000535\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.325774\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.325387\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.32518\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.324969\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.324762\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.324573\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.324357\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.324136\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.323934\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.323722\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.323511\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.323299\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.323074\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.322867\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.32266\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.322449\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.322233\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.32203\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.321823\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.321607\n",
      "ep 136: game finished, reward: -1.000000, epsilon: 0.321382\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.914643. avg accuracy: 0.812615. avg loss: -947.961425\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.32118\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.320793\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.320599\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.320388\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.320172\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.319965\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.319744\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.319524\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.319308\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.319105\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.318898\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.318696\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.318502\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.3183\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.318088\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.317881\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.317674\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.317454\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.317242\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.317031\n",
      "ep 137: game finished, reward: -1.000000, epsilon: 0.316824\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.925496. avg accuracy: 0.817613. avg loss: -955.430826\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.316617\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.316239\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.316023\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.315825\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.315631\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.315424\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.315217\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.315024\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.314826\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.314601\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.31438\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.314178\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.313939\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.313723\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.31353\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.313318\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.313107\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.312891\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.312684\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.312486\n",
      "ep 138: game finished, reward: -1.000000, epsilon: 0.312274\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.936241. avg accuracy: 0.816353. avg loss: -930.472780\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.312076\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.311685\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.311482\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.311262\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.311041\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.310816\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.310618\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.310425\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.310213\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.310006\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.309795\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.309583\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.309381\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.309169\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.308967\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.308755\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.308535\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.308328\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.308116\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.307905\n",
      "ep 139: game finished, reward: -1.000000, epsilon: 0.307693\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.946879. avg accuracy: 0.809862. avg loss: -927.347511\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.307495\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.307095\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.306892\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.306681\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.306474\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.306267\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.30606\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.305848\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.305646\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.305439\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.305241\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.30502\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.304813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 140: game finished, reward: -1.000000, epsilon: 0.304602\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.304399\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.304179\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.303972\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.303769\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.303553\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.303342\n",
      "ep 140: game finished, reward: -1.000000, epsilon: 0.303135\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.957410. avg accuracy: 0.796979. avg loss: -1043.324835\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.302937\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.302554\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.302343\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.302136\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.301911\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.301713\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.301506\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.301281\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.301078\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.300858\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.30066\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.300462\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.300246\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.300016\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.299818\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.29962\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.299427\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.299215\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.299004\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.298801\n",
      "ep 141: game finished, reward: -1.000000, epsilon: 0.298594\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.967836. avg accuracy: 0.832918. avg loss: -824.960719\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.298387\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.298005\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.297802\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.297591\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.297388\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.297172\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.29697\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.296749\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.296533\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.296313\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.296106\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.295894\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.295678\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.295471\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.295255\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.295048\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.294841\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.294634\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.294409\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.294211\n",
      "ep 142: game finished, reward: -1.000000, epsilon: 0.294004\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.978158. avg accuracy: 0.818928. avg loss: -939.448383\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.29377\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.293383\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.293185\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.292978\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.292771\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.292537\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.292339\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.292132\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.291921\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.291709\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.291484\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.291277\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.291066\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.29085\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.290625\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.290413\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.290202\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.289981\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.28977\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.289581\n",
      "ep 143: game finished, reward: -1.000000, epsilon: 0.289369\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.988376. avg accuracy: 0.799357. avg loss: -1121.676726\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.289153\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.288762\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.288568\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.288361\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.288159\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.287947\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.287736\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.287533\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.287331\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.28711\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.286894\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.286683\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.28648\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.286273\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.286057\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.285846\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.285648\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.285436\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.285216\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.285013\n",
      "ep 144: game finished, reward: -1.000000, epsilon: 0.284811\n",
      "resetting env. episode reward total was -21.000000. running mean: -19.998492. avg accuracy: 0.826818. avg loss: -1227.614500\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.284586\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.284212\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.284001\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.28378\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.283564\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.283335\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.283128\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.282934\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.282714\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.282507\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.282304\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.282102\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.281886\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.281679\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.281458\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.281242\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.281049\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.280828\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.280612\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.280387\n",
      "ep 145: game finished, reward: -1.000000, epsilon: 0.280171\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.008507. avg accuracy: 0.823938. avg loss: -982.251736\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.279969\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.279573\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.279366\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.279154\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.278938\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.278727\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.278515\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.278308\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.278088\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.277881\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.277674\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.277449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 146: game finished, reward: -1.000000, epsilon: 0.277242\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.277026\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.276805\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.276603\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.276405\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.276198\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.275991\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.275784\n",
      "ep 146: game finished, reward: -1.000000, epsilon: 0.275577\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.018422. avg accuracy: 0.846413. avg loss: -719.921279\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.275365\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.274996\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.274785\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.274564\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.274357\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.274155\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.273939\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.273727\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.273516\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.273309\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.273106\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.272886\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.272665\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.272445\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.272242\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.27204\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.271819\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.271617\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.271414\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.271207\n",
      "ep 147: game finished, reward: -1.000000, epsilon: 0.271009\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.028238. avg accuracy: 0.831538. avg loss: -684.276422\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.270802\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.270424\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.270208\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.270006\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.269808\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.269596\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.269389\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.269173\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.268962\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.268755\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.268539\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.268341\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.268134\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.267918\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.267693\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.267477\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.267261\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.267054\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.266856\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.266644\n",
      "ep 148: game finished, reward: -1.000000, epsilon: 0.266424\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.037956. avg accuracy: 0.849520. avg loss: -690.718170\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.266208\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.265825\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.265609\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.265398\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.2652\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.264975\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.264759\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.264556\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.26434\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.264133\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.263926\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.26371\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.263499\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.263292\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.263071\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.262855\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.262648\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.262441\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.262239\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.262018\n",
      "ep 149: game finished, reward: -1.000000, epsilon: 0.261807\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.047576. avg accuracy: 0.847844. avg loss: -704.886389\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.261595\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.261208\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.261001\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.260785\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.260578\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.260362\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.260155\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.259935\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.259732\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.259494\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.259278\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.259062\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.25885\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.258643\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.258432\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.258225\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.258018\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.257802\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.25759\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.257379\n",
      "ep 150: game finished, reward: -1.000000, epsilon: 0.257181\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.057100. avg accuracy: 0.850771. avg loss: -859.477504\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.256983\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.256591\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.256384\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.256182\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.255975\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.255759\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.255552\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.255322\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.25512\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.254899\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.254683\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.254476\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.254278\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.254067\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.253873\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.253671\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.253464\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.253243\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.253027\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.252838\n",
      "ep 151: game finished, reward: -1.000000, epsilon: 0.252622\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.066529. avg accuracy: 0.845503. avg loss: -764.254218\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.25242\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.252046\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.251839\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.251637\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.251425\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.251209\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.250989\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.250782\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.250557\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.250359\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.250156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 152: game finished, reward: -1.000000, epsilon: 0.249954\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.249733\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.249517\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.249292\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.249072\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.248869\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.24868\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.248469\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.248262\n",
      "ep 152: game finished, reward: -1.000000, epsilon: 0.248041\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.075864. avg accuracy: 0.848423. avg loss: -600.524126\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.247825\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.247429\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.247231\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.247024\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.246808\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.246579\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.246363\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.246138\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.245931\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.245715\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.245499\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.245283\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.245067\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.244851\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.244644\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.244441\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.244248\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.244045\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.243834\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.243631\n",
      "ep 153: game finished, reward: -1.000000, epsilon: 0.24342\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.085105. avg accuracy: 0.833379. avg loss: -896.370153\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.243204\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.242821\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.242628\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.242412\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.242205\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.241989\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.241773\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.241566\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.241363\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.241161\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.240963\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.240769\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.240553\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.240342\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.240139\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.239932\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.23973\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.239514\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.239311\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.239091\n",
      "ep 154: game finished, reward: -1.000000, epsilon: 0.238888\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.094254. avg accuracy: 0.837820. avg loss: -845.993496\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.238663\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.238267\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.238056\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.237831\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.23761\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.23739\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.237169\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.236953\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.236737\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.236521\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.236296\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.236098\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.235882\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.235684\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.235473\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.235266\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.235045\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.234829\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.234636\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.234402\n",
      "ep 155: game finished, reward: -1.000000, epsilon: 0.234199\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.103312. avg accuracy: 0.853160. avg loss: -728.105741\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.233979\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.233619\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.233394\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.233187\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.232975\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.232755\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.232566\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.232359\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.232156\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.231967\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.23176\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.231553\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.231355\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.231139\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.230923\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.230716\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.2305\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.230298\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.230082\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.22987\n",
      "ep 156: game finished, reward: -1.000000, epsilon: 0.229645\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.112279. avg accuracy: 0.839268. avg loss: -696.119893\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.229429\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.229024\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.228813\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.228601\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.22839\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.228187\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.227976\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.227782\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.227562\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.22735\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.227134\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.226927\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.226729\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.226509\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.22632\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.226099\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.225883\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.225676\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.225469\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.225253\n",
      "ep 157: game finished, reward: -1.000000, epsilon: 0.225042\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.121156. avg accuracy: 0.836027. avg loss: -671.698462\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.22483\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.224452\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.224245\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.224034\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.223827\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.223615\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.22339\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.22317\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.222963\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.222751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 158: game finished, reward: -1.000000, epsilon: 0.222517\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.22231\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.222103\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.221896\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.22168\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.221469\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.221262\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.221055\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.220852\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.220636\n",
      "ep 158: game finished, reward: -1.000000, epsilon: 0.22042\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.129944. avg accuracy: 0.860117. avg loss: -605.338318\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.220204\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.219813\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.219601\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.219394\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.219174\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.218958\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.218751\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.218553\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.218355\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.218152\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.217941\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.217734\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.217527\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.217315\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.217113\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.216897\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.216676\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.216474\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.216267\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.21606\n",
      "ep 159: game finished, reward: -1.000000, epsilon: 0.215844\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.138645. avg accuracy: 0.868383. avg loss: -1016.872679\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.215641\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.215263\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.215056\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.214845\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.214638\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.214431\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.214215\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.213994\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.213783\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.21358\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.213378\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.21318\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.212982\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.212775\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.212559\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.212352\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.212145\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.211929\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.211717\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.21151\n",
      "ep 160: game finished, reward: -1.000000, epsilon: 0.211294\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.147258. avg accuracy: 0.865982. avg loss: -841.848892\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.211083\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.210714\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.210507\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.210291\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.210084\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.209863\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.209661\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.209449\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.209251\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.209053\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.208846\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.208626\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.208423\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.208225\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.208018\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.207807\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.207591\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.20737\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.207163\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.206952\n",
      "ep 161: game finished, reward: -1.000000, epsilon: 0.206749\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.155786. avg accuracy: 0.858471. avg loss: -749.975258\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.206551\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.20616\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.205957\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.20575\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.205539\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.205327\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.205111\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.204886\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.20467\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.20445\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.204234\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.204022\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.203815\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.203613\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.203397\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.203194\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.202974\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.202767\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.20256\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.202362\n",
      "ep 162: game finished, reward: -1.000000, epsilon: 0.20215\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.164228. avg accuracy: 0.855054. avg loss: -1017.384681\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.201948\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.201561\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.201358\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.201156\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.200935\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.200724\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.200517\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.20031\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.200103\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.199905\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.199684\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.199495\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.199288\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.199072\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.19887\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.198649\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.198433\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.198217\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.198006\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.197799\n",
      "ep 163: game finished, reward: -1.000000, epsilon: 0.197569\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.172586. avg accuracy: 0.877373. avg loss: -938.391270\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.197358\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.196984\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.196786\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.196584\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.196377\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.196174\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.195967\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.19576\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.195562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 164: game finished, reward: -1.000000, epsilon: 0.195346\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.195135\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.194919\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.194716\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.194509\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.194307\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.194086\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.193875\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.193663\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.193447\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.193231\n",
      "ep 164: game finished, reward: -1.000000, epsilon: 0.19302\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.180860. avg accuracy: 0.883106. avg loss: -499.849810\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.192808\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.192412\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.192201\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.191998\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.191791\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.191571\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.19135\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.191139\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.190936\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.190725\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.190522\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.190324\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.190104\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.189888\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.18969\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.189487\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.189276\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.189055\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.188848\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.188641\n",
      "ep 165: game finished, reward: -1.000000, epsilon: 0.188443\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.189051. avg accuracy: 0.884656. avg loss: -863.810060\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.188227\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.187849\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.187638\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.187426\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.18721\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.186994\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.186787\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.186562\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.186369\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.186148\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.185946\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.185721\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.185518\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.185307\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.185104\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.184893\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.184686\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.18447\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.184263\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.184042\n",
      "ep 166: game finished, reward: -1.000000, epsilon: 0.183822\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.197161. avg accuracy: 0.890127. avg loss: -961.097490\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.183606\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.183214\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.183003\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.182805\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.182602\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.182382\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.182161\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.181954\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.181747\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.181549\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.181347\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.18114\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.180928\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.180721\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.180505\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.180298\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.180091\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.179889\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.179682\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.179475\n",
      "ep 167: game finished, reward: -1.000000, epsilon: 0.179281\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.205189. avg accuracy: 0.890606. avg loss: -506.285065\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.179074\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.178687\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.178467\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.178255\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.178035\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.177828\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.177616\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.177405\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.177202\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.176982\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.176784\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.176577\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.17637\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.176163\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.175947\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.175749\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.175533\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.175326\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.175119\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.174916\n",
      "ep 168: game finished, reward: -1.000000, epsilon: 0.174714\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.213137. avg accuracy: 0.884897. avg loss: -876.618411\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.174498\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.174106\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.173895\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.173679\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.173463\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.173269\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.173067\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.172851\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.17263\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.172432\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.17223\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.172014\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.171798\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.1716\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.171379\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.171172\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.170965\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.170754\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.170556\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.170344\n",
      "ep 169: game finished, reward: -1.000000, epsilon: 0.170133\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.221006. avg accuracy: 0.902323. avg loss: -785.606084\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.169926\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.169539\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.169332\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.169134\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.168931\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.168729\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.168526\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.168306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 170: game finished, reward: -1.000000, epsilon: 0.168081\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.167883\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.167676\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.167478\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.167275\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.167073\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.166866\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.166668\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.166461\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.166258\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.166042\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.16584\n",
      "ep 170: game finished, reward: -1.000000, epsilon: 0.165624\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.228796. avg accuracy: 0.898229. avg loss: -757.900099\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.165403\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.165012\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.164805\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.164575\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.164364\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.164152\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.163941\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.163729\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.163509\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.163288\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.16309\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.162865\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.162649\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.162433\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.162235\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.162037\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.161817\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.161619\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.161403\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.161196\n",
      "ep 171: game finished, reward: -1.000000, epsilon: 0.160998\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.236508. avg accuracy: 0.901346. avg loss: -976.851996\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.160791\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.160395\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.160179\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.159967\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.159751\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.159531\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.159319\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.159112\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.158914\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.158703\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.158491\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.158284\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.158077\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.157866\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.157663\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.157456\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.157249\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.157033\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.156831\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.156615\n",
      "ep 172: game finished, reward: -1.000000, epsilon: 0.156408\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.244143. avg accuracy: 0.913301. avg loss: -687.346412\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.156196\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.155823\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.155611\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.155386\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.155184\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.154963\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.154747\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.154536\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.154329\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.154104\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.153892\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.153681\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.153478\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.153262\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.15306\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.152839\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.152632\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.152425\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.152227\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.152011\n",
      "ep 173: game finished, reward: -1.000000, epsilon: 0.151813\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.251701. avg accuracy: 0.902096. avg loss: -710.440847\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.151602\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.151228\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.151026\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.150823\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.150607\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.150418\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.150193\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.149973\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.149752\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.149532\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.149316\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.149109\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.148902\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.148686\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.148474\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.148258\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.148047\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.147835\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.147628\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.147408\n",
      "ep 174: game finished, reward: -1.000000, epsilon: 0.14721\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.259184. avg accuracy: 0.912339. avg loss: -453.013060\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.146985\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.14662\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.146413\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.146215\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.146008\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.145801\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.14559\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.145396\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.145185\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.144964\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.144753\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.144537\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.14433\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.144127\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.143916\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.1437\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.143506\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.143295\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.143097\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.142903\n",
      "ep 175: game finished, reward: -1.000000, epsilon: 0.142674\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.266593. avg accuracy: 0.908546. avg loss: -481.089306\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.142467\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.142071\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.141868\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.141657\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.141445\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.141243\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.141036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 176: game finished, reward: -1.000000, epsilon: 0.140824\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.140617\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.140406\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.140199\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.139969\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.139753\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.139546\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.13933\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.139128\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.138916\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.1387\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.138475\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.138268\n",
      "ep 176: game finished, reward: -1.000000, epsilon: 0.138052\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.273927. avg accuracy: 0.923603. avg loss: -520.027639\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.137845\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.137454\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.137247\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.137026\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.136824\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.136617\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.136419\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.136216\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.135996\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.135802\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.135591\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.135384\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.135172\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.134965\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.134749\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.134538\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.13434\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.134146\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.133953\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.133737\n",
      "ep 177: game finished, reward: -1.000000, epsilon: 0.133525\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.281187. avg accuracy: 0.908040. avg loss: -727.579351\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.133323\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.13294\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.132724\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.132508\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.132306\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.13209\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.131874\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.131653\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.13146\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.131239\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.131032\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.130825\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.130627\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.130402\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.1302\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.129984\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.129763\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.129556\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.129354\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.129151\n",
      "ep 178: game finished, reward: -1.000000, epsilon: 0.128931\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.288375. avg accuracy: 0.928963. avg loss: -559.067025\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.128724\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.128346\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.128143\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.127927\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.127725\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.127518\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.127302\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.127095\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.126888\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.126681\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.126483\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.12628\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.126078\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.125871\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.125677\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.125479\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.125254\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.125034\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.124822\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.124615\n",
      "ep 179: game finished, reward: -1.000000, epsilon: 0.124395\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.295492. avg accuracy: 0.925870. avg loss: -521.429316\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.12417\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.123783\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.123562\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.123355\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.123144\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.122928\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.122707\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.122509\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.122329\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.122122\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.12192\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.121704\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.121479\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.121258\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.121051\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.120831\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.120606\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.120394\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.120187\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.11998\n",
      "ep 180: game finished, reward: -1.000000, epsilon: 0.119764\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.302537. avg accuracy: 0.904702. avg loss: -548.531924\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.119557\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.119157\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.118936\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.118711\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.118522\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.118315\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.118095\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.117879\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.117658\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.117451\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.117231\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.117024\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.116812\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.11661\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.116398\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.116191\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.115975\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.115759\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.115543\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.115327\n",
      "ep 181: game finished, reward: -1.000000, epsilon: 0.115111\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.309511. avg accuracy: 0.922048. avg loss: -693.414696\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.1149\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.114513\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.114324\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.114121\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.113896\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.11368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 182: game finished, reward: -1.000000, epsilon: 0.11346\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.113248\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.113046\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.112843\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.112636\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.112425\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.112213\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.11202\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.111804\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.111592\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.111385\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.111174\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.110971\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.11076\n",
      "ep 182: game finished, reward: -1.000000, epsilon: 0.110562\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.316416. avg accuracy: 0.926752. avg loss: -605.586062\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.110355\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.109972\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.109752\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.109536\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.109333\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.109113\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.108906\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.108685\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.108474\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.108267\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.108051\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.107835\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.107623\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.107412\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.1072\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.106989\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.106786\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.106588\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.106377\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.106152\n",
      "ep 183: game finished, reward: -1.000000, epsilon: 0.105945\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.323252. avg accuracy: 0.932749. avg loss: -326.323622\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.105738\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.105355\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.105144\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.104932\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.104721\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.104523\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.104329\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.104122\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.103906\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.103695\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.103501\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.103285\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.103083\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.10288\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.102669\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.102466\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.102273\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.102057\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.101854\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.101665\n",
      "ep 184: game finished, reward: -1.000000, epsilon: 0.101454\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.330020. avg accuracy: 0.922740. avg loss: -568.957646\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.101238\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.100851\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.100648\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.100414\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.100203\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 185: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.336719. avg accuracy: 0.937797. avg loss: -512.625739\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 186: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.343352. avg accuracy: 0.928574. avg loss: -702.420969\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 187: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.349919. avg accuracy: 0.943376. avg loss: -452.673848\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 188: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.356420. avg accuracy: 0.917936. avg loss: -555.525524\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 189: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.362855. avg accuracy: 0.924405. avg loss: -607.928059\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 190: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.369227. avg accuracy: 0.941204. avg loss: -686.591565\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 191: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.375535. avg accuracy: 0.954659. avg loss: -463.009928\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 192: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.381779. avg accuracy: 0.939864. avg loss: -193.191343\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 193: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.387961. avg accuracy: 0.934217. avg loss: -508.748658\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 194: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.394082. avg accuracy: 0.928462. avg loss: -389.304258\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 195: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.400141. avg accuracy: 0.917453. avg loss: -557.909681\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 196: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.406140. avg accuracy: 0.938909. avg loss: -289.782990\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 197: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.412078. avg accuracy: 0.934985. avg loss: -731.692819\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 198: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.417957. avg accuracy: 0.948682. avg loss: -673.452212\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 199: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.423778. avg accuracy: 0.935770. avg loss: -726.135602\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 200: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.429540. avg accuracy: 0.941502. avg loss: -637.889434\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 201: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.435245. avg accuracy: 0.943297. avg loss: -393.031952\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 202: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.440892. avg accuracy: 0.943216. avg loss: -238.330904\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 203: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.446483. avg accuracy: 0.942817. avg loss: -746.744895\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 204: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.452018. avg accuracy: 0.933399. avg loss: -389.374037\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 205: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.457498. avg accuracy: 0.941861. avg loss: -542.466459\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 206: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.462923. avg accuracy: 0.931401. avg loss: -509.017960\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 207: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.468294. avg accuracy: 0.938939. avg loss: -345.828586\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 208: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.473611. avg accuracy: 0.940020. avg loss: -390.683655\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 209: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.478875. avg accuracy: 0.931972. avg loss: -490.040520\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 210: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.484086. avg accuracy: 0.948187. avg loss: -673.107968\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 211: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.489245. avg accuracy: 0.946383. avg loss: -291.000449\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 212: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.494353. avg accuracy: 0.942483. avg loss: -421.453383\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 213: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.499409. avg accuracy: 0.927021. avg loss: -707.490083\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 214: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.504415. avg accuracy: 0.942708. avg loss: -362.264531\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 215: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.509371. avg accuracy: 0.945748. avg loss: -323.321281\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 216: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.514277. avg accuracy: 0.942233. avg loss: -367.116996\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 217: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.519135. avg accuracy: 0.940296. avg loss: -659.287214\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 218: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.523943. avg accuracy: 0.924911. avg loss: -746.522524\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 219: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.528704. avg accuracy: 0.926667. avg loss: -825.881299\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 220: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.533417. avg accuracy: 0.929463. avg loss: -596.699480\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 221: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.538083. avg accuracy: 0.933849. avg loss: -555.790353\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 222: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.542702. avg accuracy: 0.935407. avg loss: -609.485698\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 223: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.547275. avg accuracy: 0.936575. avg loss: -585.358485\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 224: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.551802. avg accuracy: 0.947102. avg loss: -75.119121\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 225: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.556284. avg accuracy: 0.954907. avg loss: -606.915306\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 226: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.560721. avg accuracy: 0.923808. avg loss: -800.562543\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 227: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.565114. avg accuracy: 0.942885. avg loss: -429.953416\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 228: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.569463. avg accuracy: 0.936828. avg loss: -736.250483\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 229: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.573768. avg accuracy: 0.933091. avg loss: -348.047316\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 230: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.578031. avg accuracy: 0.945191. avg loss: -498.165875\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 231: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.582250. avg accuracy: 0.937022. avg loss: -627.589484\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 232: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.586428. avg accuracy: 0.929401. avg loss: -513.414686\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 233: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.590563. avg accuracy: 0.929722. avg loss: -895.556077\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 234: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.594658. avg accuracy: 0.918361. avg loss: -539.621948\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 235: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.598711. avg accuracy: 0.951693. avg loss: -709.215172\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 236: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.602724. avg accuracy: 0.943719. avg loss: -460.165851\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 237: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.606697. avg accuracy: 0.949822. avg loss: -561.746464\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 238: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.610630. avg accuracy: 0.926574. avg loss: -740.057638\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 239: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resetting env. episode reward total was -21.000000. running mean: -20.614524. avg accuracy: 0.931547. avg loss: -696.430552\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 240: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.618378. avg accuracy: 0.927976. avg loss: -866.276781\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 241: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.622195. avg accuracy: 0.939438. avg loss: -598.225551\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 242: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.625973. avg accuracy: 0.939315. avg loss: -279.419963\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 243: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.629713. avg accuracy: 0.940910. avg loss: -577.763545\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 244: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.633416. avg accuracy: 0.933366. avg loss: -448.632839\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 245: game finished, reward: -1.000000, epsilon: 0.1\n",
      "resetting env. episode reward total was -21.000000. running mean: -20.637082. avg accuracy: 0.943711. avg loss: -407.939471\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n",
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 246: game finished, reward: -1.000000, epsilon: 0.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0f08b730647c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 eps_greedy_frames, resume = False, render = False)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-41c530eaec0d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-41c530eaec0d>\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mup_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mup_prob\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4203\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4204\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3515\u001b[0m           \u001b[0mautograph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3516\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m-> 3517\u001b[0;31m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3518\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3519\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(function)\u001b[0m\n\u001b[1;32m   3791\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m   3792\u001b[0m         \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3793\u001b[0;31m         Function(\n\u001b[0m\u001b[1;32m   3794\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3795\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, python_function, name, input_signature, attributes, autograph, autograph_options, experimental_relax_shapes, capture_by_value, experimental_compile, experimental_follow_type_hints)\u001b[0m\n\u001b[1;32m   2910\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m     \u001b[0mpure_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattributes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mIMPLEMENTS_ATTRIBUTE_NAME\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m     self._function_spec = FunctionSpec.from_function_and_signature(\n\u001b[0m\u001b[1;32m   2913\u001b[0m         \u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0minput_signature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mfrom_function_and_signature\u001b[0;34m(python_function, input_signature, is_pure, experimental_follow_type_hints, experimental_compile)\u001b[0m\n\u001b[1;32m   2336\u001b[0m       \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mFunctionSpec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2337\u001b[0m     \"\"\"\n\u001b[0;32m-> 2338\u001b[0;31m     \u001b[0mfullargspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_inspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2339\u001b[0m     \u001b[0;31m# Treat a wrapped partial function as a special case. For all arguments that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[0;31m# were overridden with keywords in the partial:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/tf_inspect.py\u001b[0m in \u001b[0;36mgetfullargspec\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mdirectly\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \"\"\"\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0mdecorators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecorators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"Pong-v0\")\n",
    "\n",
    "mem = Memory(50_000)\n",
    "\n",
    "eps = 1.0\n",
    "max_eps = 1.0\n",
    "min_eps = 0.1\n",
    "eps_greedy_frames = 200000.0\n",
    "\n",
    "game_dimensions = 80*80\n",
    "\n",
    "gr = GameRunner(env, model, target_model, mem, eps, max_eps, min_eps, game_dimensions, \n",
    "                eps_greedy_frames, resume = False, render = False)\n",
    "\n",
    "gr.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7edcd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 255, (210, 160, 3), uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a84545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_action_meanings()\n",
    "\n",
    "# NOOP is the same as FIRE (standing still)\n",
    "# LEFT is the same as LEFTFIRE (down)\n",
    "# RIGHT is the same as RIGHTFIRE (up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c088a1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(): 0, (32,): 1, (100,): 2, (97,): 3, (32, 100): 4, (32, 97): 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.unwrapped.get_keys_to_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c696ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ControlRRLR1e-3.txt\", \"rb\") as fp:   # Unpickling\n",
    "        running_rewards = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3eb8125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(range(1000), running_rewards[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa8e720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
